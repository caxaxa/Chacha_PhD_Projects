{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMlP7FIeV5EgoLShEt2+cxD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caxaxa/Chacha_PhD_Projects/blob/master/My_ML_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZo-NBNP5qur"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle\n",
        "\n",
        "#Download kaggle.json\n",
        "# more info on: https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer to Kaggle dircetorz\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "l9FFk3TC82Av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Allocate the required permission for this file.\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "Qlb1ehK3ISzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Dataset\n",
        "! kaggle datasets download rvasel/qconcursos"
      ],
      "metadata": {
        "id": "mZ4r8ZbRIpGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Unziping\n",
        "!unzip '/content/qconcursos.zip'"
      ],
      "metadata": {
        "id": "IDC75nJDJJJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Enabling GPUs\n",
        "\n",
        "#print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "id": "iI8cwjQixqZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type_dict = {'created_at' : 'str',\n",
        "'commented_by_professor'    :'int',\n",
        "'difficulty'                :'int',\n",
        "'discipline_id'             :'int',\n",
        "'examining_board_id'        :'int',\n",
        "'knowledge_area_id'         :'int',\n",
        "'modality_id'               :'int',\n",
        "'nullified'                 :'int',\n",
        "'outdated'                  :'int',\n",
        "'product_id'                :'int',\n",
        "'institute_id'              :'int',\n",
        "'publication_year'          :'int',\n",
        "'scholarity_id'             :'int'}"
      ],
      "metadata": {
        "id": "2Ljuqps_x-CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building the datasets\n",
        "import pandas as pd\n",
        "\n",
        "df_model = pd.read_csv('/content/Dataset_model.csv')\n",
        "df_questions = pd.read_csv('/content/subjects_questions.csv')\n",
        "sub_example  = pd.read_csv('/content/Submit.csv',sep =';')"
      ],
      "metadata": {
        "id": "gZ1RJglFJ4ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dxo_qU2nx85Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map the subjecti id from novo_question_id\n",
        "#Note, rearrage the columns before turning into dict\n",
        "df_model['subject_id'] = df_model['novo_question_id'].map(df_questions[['novo_question_id','subject_id']].to_dict())"
      ],
      "metadata": {
        "id": "gyeKcWJOKkct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting rid of NaNs\n",
        "\n",
        "integers = ['novo_user_id','commented_by_professor','difficulty','discipline_id','examining_board_id', 'knowledge_area_id',\n",
        "       'modality_id', 'nullified', 'outdated', 'product_id','institute_id',\n",
        "       'publication_year', 'scholarity_id', 'novo_question_id','row']\n",
        "\n",
        "df_model[integers]= df_model[integers].fillna(1000) \n",
        "df_model = df_model.fillna('NAO CONSTA')"
      ],
      "metadata": {
        "id": "_c5QwiIk2HVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setting correct dtypes\n",
        "\n",
        "df_model = df_model.astype(type_dict)"
      ],
      "metadata": {
        "id": "UX9BRDVk2Iqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6tc_anl12VJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature created at to timestamp\n",
        "#change datetime to timestamp\n",
        "#df_model['created_at'] = df_model[['created_at']].apply(lambda x: x[0].datetime(), axis=1).astype()\n",
        "df_model = df_model.drop(['created_at'],axis = 1)\n"
      ],
      "metadata": {
        "id": "ijwjGb3eynp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kAkFJEvw2GhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7arxQtK6LcEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "NxgYGP_bOq1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building and encoding features and target on Keras"
      ],
      "metadata": {
        "id": "CoIA-hQ_XYsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Libraries\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "yKtC-xA_Xc_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kz1y2wi6ZLOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building and encoding features and target on Keras\n",
        "\n",
        "val_dataframe = df_model.sample(frac=0.2, random_state=1337)\n",
        "train_dataframe = df_model.drop(val_dataframe.index)\n",
        "\n",
        "print(\n",
        "    \"Using %d samples for training and %d for validation\"\n",
        "    % (len(train_dataframe), len(val_dataframe))\n",
        ")"
      ],
      "metadata": {
        "id": "cIjL9RI_PzeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def dataframe_to_dataset(dataframe):\n",
        "    dataframe = dataframe.copy()\n",
        "    labels = dataframe.pop(\"acertou\")\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "    return ds\n",
        "\n",
        "\n",
        "train_ds = dataframe_to_dataset(train_dataframe)\n",
        "val_ds = dataframe_to_dataset(val_dataframe)"
      ],
      "metadata": {
        "id": "Cryy-7nBXTdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Xxo6VoTZAKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in train_ds.take(1):\n",
        "    print(\"Input:\", x)\n",
        "    print(\"Target:\", y)"
      ],
      "metadata": {
        "id": "7crFBWOFW2Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Batching Dataset\n",
        "batch_size = 500\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "val_ds = val_ds.batch(batch_size)"
      ],
      "metadata": {
        "id": "0iljp26cGMVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q_Xy5Xp4w4Dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building one-hot encode functions"
      ],
      "metadata": {
        "id": "-51LfZnVfmvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import IntegerLookup\n",
        "from tensorflow.keras.layers import Normalization\n",
        "from tensorflow.keras.layers import StringLookup\n",
        "\n",
        "\n",
        "def encode_numerical_feature(feature, name, dataset):\n",
        "    # Create a Normalization layer for our feature\n",
        "    normalizer = Normalization()\n",
        "\n",
        "    # Prepare a Dataset that only yields our feature\n",
        "    feature_ds = dataset.map(lambda x, y: x[name])\n",
        "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
        "\n",
        "    # Learn the statistics of the data\n",
        "    normalizer.adapt(feature_ds)\n",
        "\n",
        "    # Normalize the input feature\n",
        "    encoded_feature = normalizer(feature)\n",
        "    return encoded_feature\n",
        "\n",
        "\n",
        "def encode_categorical_feature(feature, name, dataset, is_string):\n",
        "    lookup_class = StringLookup if is_string else IntegerLookup\n",
        "    # Create a lookup layer which will turn strings into integer indices\n",
        "    lookup = lookup_class(output_mode=\"binary\")\n",
        "\n",
        "    # Prepare a Dataset that only yields our feature\n",
        "    feature_ds = dataset.map(lambda x, y: x[name])\n",
        "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
        "\n",
        "    # Learn the set of possible string values and assign them a fixed integer index\n",
        "    lookup.adapt(feature_ds)\n",
        "\n",
        "    # Turn the string input into integer indices\n",
        "    encoded_feature = lookup(feature)\n",
        "    return encoded_feature"
      ],
      "metadata": {
        "id": "IeNBjdHDXFKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = df_model.columns.tolist()\n",
        "del df_model\n",
        "gc.collect()\n",
        "#with the following features being categorical:\n",
        "\n",
        "categoricals  =  integers\n",
        "\n",
        "as_string =  [x for x in inputs if x not in integers]\n",
        "as_string.remove('acertou')\n",
        "#exclude = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68','target']\n",
        "\n",
        "\n",
        "\n",
        "#list of all numerical \n",
        "\n",
        "#apparently there is no simpler sinthax to remove list of elements from a list\n",
        "\n",
        "#numericals = [x for x in inputs if x not in exclude]"
      ],
      "metadata": {
        "id": "jCvyHiUfghvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BVllVqLwlr5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the model"
      ],
      "metadata": {
        "id": "q993rpF9h1wE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorical features encoded as integers\n",
        "var_inputs= {}\n",
        "var_encoded = {}\n",
        "# for var_num in numericals:\n",
        "#     var_inputs[var_num] =  keras.Input(shape=(1,), name=var_num)\n",
        "#     var_encoded[var_num] = encode_numerical_feature(var_inputs[var_num], var_num, train_ds)"
      ],
      "metadata": {
        "id": "CfFc6Lr7hrFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hY8ng5keioiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorical feature encoded as string\n",
        "\n",
        "for var_num in as_string:\n",
        "    var_inputs[var_num] =  keras.Input(shape=(1,), name=var_num, dtype=\"string\")\n",
        "    var_encoded[var_num] = encode_categorical_feature(var_inputs[var_num], var_num, train_ds, True)"
      ],
      "metadata": {
        "id": "4dwtFrToiqaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorical features encoded as integers\n",
        "\n",
        "for var_num in categoricals:\n",
        "    var_inputs[var_num] =  keras.Input(shape=(1,), name=var_num, dtype=\"int64\")\n",
        "    var_encoded[var_num] = encode_categorical_feature(var_inputs[var_num], var_num, train_ds, False)"
      ],
      "metadata": {
        "id": "NCJ1KcEBvgYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.remove('acertou')\n",
        "\n",
        "input_list = []\n",
        "for i in inputs:\n",
        "    input_list.append(var_encoded[i])"
      ],
      "metadata": {
        "id": "BvKwGzZ-i0Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_features = layers.concatenate(input_list)\n",
        "\n",
        "x = layers.Dense(batch_size, activation=\"relu\")(all_features)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "output = layers.Dense(1, activation=\"sigmoid\")(x)"
      ],
      "metadata": {
        "id": "SNiTYPZji1q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Model(var_inputs, output)\n",
        "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"]) #try to build the f1 stat 02*(precision/recall/(preisionrecall)) see on : https://www.tensorflow.org/api_docs/python/tf/keras/metrics"
      ],
      "metadata": {
        "id": "lvHL6krHi3Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# `rankdir='LR'` is to make the graph horizontal.\n",
        "#keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
      ],
      "metadata": {
        "id": "4xuH_-2Ti4qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "umjRhk3ju2T8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_ds, epochs=50, validation_data=val_ds)"
      ],
      "metadata": {
        "id": "WzDXt4qwi8qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('my_model.tf')"
      ],
      "metadata": {
        "id": "gS8IjZNhi-Fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "UX3kcmyFjAAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bDApSQj6vRFz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}